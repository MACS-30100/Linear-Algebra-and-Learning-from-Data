{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem II.1.1\n",
    "\n",
    "Since we have $S_{i,i-1}=1$ for $i=2,\\dots,n$, so for matrix $D$, we have $d_{i,i}=1$ for $i=1,\\dots,n$ and $d_{i,i-1}=-1$ for $i=2,\\dots,n$.\n",
    "\n",
    "With column times rows we have: \n",
    "\n",
    "$SS^T = \\sum_i s_is^T_i$ where for $i \\lt n$, $s_i = \\begin{bmatrix}0 \\\\ \\vdots \\\\ 1 \\\\ 0 \\\\ \\vdots \\\\ 0\\end{bmatrix}$, the 1 appears at the $i+1$ position and $s_n = \\begin{bmatrix} 0 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{bmatrix}$. \n",
    "\n",
    "So for $i\\lt n$, we have $K^i = s_is^Ts_i$, so $K^i_{i+1,i+1} = 1$ while all other entries are zero.\n",
    "And for $i=n$, we have $K^n = 0$.\n",
    "So combine all $K^i$ together, we have $SS^T = I - K^0 = I - \\begin{bmatrix}1 & 0 & \\dots \\\\ 0 & 0 & \\dots \\\\ \\dots & \\dots & \\dots \\\\ 0 & \\dots & 0 \\end{bmatrix}$\n",
    "\n",
    "So we have $DD^T = (I-S)(I-S)^T=(I-S)(I-S^T) = I - S^T-S + SS^T = -S + 2I - S^T - K^0 = A - K^0$. \n",
    "\n",
    "So $DD^T$ equals $A$ except that the former has 1 and the latter has 2 in their $(1,1)$ entries. \n",
    "\n",
    "Similarly we can see that $D^TD$ equals to $A$ except that $1\\ne 2$ in their $(n,n)$ entries. \n",
    "\n",
    "#### Problem II.1.2\n",
    "\n",
    "For matrix $D$, we have $d_{i,i}=1$ for $i=1,\\dots,n$ and $d_{i,i-1}=-1$ for $i=2,\\dots,n$.\n",
    "For matrix $D^{-1}$, we have $d_{i,j} = 1$ if $i \\ge j$, otherwise $d_{i,j}=0$. \n",
    "\n",
    "For the product, $M=DD^{-1}$, we have $M_{i,j} = \\sum_k d_{i,k}d^{-1}_{k,j} = d_{i,i}d^{-1}_{i,j} + d_{i, i-1}d^{-1}_{i-1,j} = d^{-1}_{i,j} - d^{-1}_{i-1,j}$\n",
    "\n",
    "* If $i < j$, we have $M_{i,j} = 0 - 0 = 0$\n",
    "* If $i = j$, we have $M_{i,j} = 1 - 0 = 1$,\n",
    "* If $i \\ge j + 1 $, we have $M_{i,j} = 1 - 1 = 0$\n",
    "\n",
    "So $M=I=DD^{-1}$.\n",
    "\n",
    "If $n=4$, we have $D^{-1} = \\begin{bmatrix} 1 & 0 & 0 & 0\\\\1 & 1 & 0 & 0 \\\\ 1 & 1 & 1 & 0 \\\\ 1 & 1 & 1 &1 \\end{bmatrix}$\n",
    "so $(D^{-1})^T = \\begin{bmatrix} 1 & 1 & 1 & 1\\\\0 & 1 & 1 & 1 \\\\ 0 & 0 & 1 & 1\\\\ 0 & 0 & 0 &1 \\end{bmatrix}$\n",
    "\n",
    "Then $(DD^T)^{-1} = (D^{-1})^TD^{-1} = \\begin{bmatrix} 4& 3 & 2 & 1\\\\3 & 3 & 2 & 1 \\\\ 2 & 2 & 2 & 1\\\\ 1 & 1 & 1 &1 \\end{bmatrix}$\n",
    "\n",
    "#### Problem II.1.3\n",
    "\n",
    "Problem 1 says that $A=DD^T + ee^T$, where $e=(1,0,\\dots,0)$. From secition III.1 we have $A^{-1} = (DD^T)^{-1} - zz^T$. \n",
    "\n",
    "We see that $AA^{-1} = (DD^T + ee^T)((DD^T)^{-1} - zz^T) = I - DD^Tzz^T + ee^T(DD^T)^{-1} - ee^Tzz^T$\n",
    "For $n=3$, we have $DD^T = \\begin{bmatrix} 1& -1 & 0\\\\-1 & 2 & -1 \\\\ 0 & -1 & 2\\end{bmatrix}$, and $(DD^T)^{-1}= \\begin{bmatrix} 3 & 2 & 1\\\\2 & 2 & 1\\\\ 1 & 1 & 1 \\end{bmatrix}$, $ee^T = \\begin{bmatrix} 1& 0 & 0\\\\0 & 0 & 0 \\\\ 0 & 0 & 0\\end{bmatrix}$, let $z=(z_1,z_2,z_3)$, we have\n",
    "\n",
    "$DD^Tzz^T = \\begin{bmatrix} z_1(z_1-z_2)& z_2(z_1-z_2) & z_3(z_1-z_2)\\\\z_1(2z_2-z_1-z_3) & z_2(2z_2-z_1-z_3) & z_3(2z_2-z_1-z_3) \\\\ z_1(2z_3-z_2) & z_2(2z_3-z_2) & z_3(2z_3-z_2)\\end{bmatrix}$\n",
    "\n",
    "$ee^T(DD^T)^{-1} = \\begin{bmatrix} 3 & 2 & 1\\\\0 & 0 & 0\\\\ 0 & 0 & 0 \\end{bmatrix}$\n",
    "\n",
    "$ee^Tzz^T = \\begin{bmatrix} z^2_1 & z_1z_2 & z_1z_3\\\\ 0 & 0 & 0\\\\ 0 & 0 & 0 \\end{bmatrix}$\n",
    "\n",
    "So we have $z_3(2z_3-z_2) = 0$, $z_3(2z_2-z_1-z_3)= 0$, and $-z_1(z_1-z_2)+3-z^2_1=0$ we see that $z=(\\frac{3}{2},1,\\frac{1}{2})$ can be a solution here.\n",
    "\n",
    "\n",
    "So rank-1 change in $DD^T$ produces rank-1 change in its inverse.\n",
    "\n",
    "#### Problem II.1.4\n",
    "\n",
    "Check matrix $M=(-S+2I)^{-1}S^T$.\n",
    "\n",
    "* For $n=2$, we have $S=\\begin{bmatrix}0 & 0 \\\\ 1 & 0 \\end{bmatrix}$, $S^T=\\begin{bmatrix}0 & 1 \\\\ 0 & 0 \\end{bmatrix}$, $-S+2I = \\begin{bmatrix}2 & 0 \\\\ -1 & 2 \\end{bmatrix}$, so $(-S+2I)^{-1} = \\begin{bmatrix}\\frac{1}{2} & 0 \\\\ \\frac{1}{4} & \\frac{1}{2}\\end{bmatrix}$ and $M=(-S+2I)^{-1}S^T = \\begin{bmatrix}\\frac{1}{2} & 0 \\\\ \\frac{1}{4} & \\frac{1}{2}\\end{bmatrix} \\begin{bmatrix}0 & 1 \\\\ 0 & 0 \\end{bmatrix} = \\begin{bmatrix}0 & \\frac{1}{2}  \\\\ 0 & \\frac{1}{4}\\end{bmatrix} $. The matrix $M$ has eigenvalues $\\lambda_1 = 0, \\lambda_2 = \\frac{1}{4}$.\n",
    "\n",
    "* For $n=3$, we have $S=\\begin{bmatrix}0 & 0 & 0 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix}$, $S^T=\\begin{bmatrix}0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 0 & 0 & 0\\end{bmatrix}$, $-S+2I = \\begin{bmatrix}2 & 0 & 0 \\\\ -1 & 2 & 0 \\\\ 0 &-1 & 2 \\end{bmatrix}$, so $(-S+2I)^{-1} = \\begin{bmatrix}\\frac{1}{2} & 0 & 0\\\\ \\frac{1}{4} & \\frac{1}{2} & 0 \\\\ \\frac{1}{8} & \\frac{1}{4}& \\frac{1}{2}\\end{bmatrix}$ and $M=(-S+2I)^{-1}S^T = \\begin{bmatrix}\\frac{1}{2} & 0 & 0\\\\ \\frac{1}{4} & \\frac{1}{2} & 0 \\\\ \\frac{1}{8} & \\frac{1}{4}& \\frac{1}{2}\\end{bmatrix}  \\begin{bmatrix}0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 0 & 0 & 0\\end{bmatrix} = \\begin{bmatrix}0 & \\frac{1}{2} &0  \\\\ 0 & \\frac{1}{4} & \\frac{1}{2} \\\\ 0 & \\frac{1}{8} & \\frac{1}{4}\\end{bmatrix} $. The matrix $M$ has eigenvalues $\\lambda_1 = 0, \\lambda_{2,3} = \\frac{1}{4}$.\n",
    "\n",
    "#### Problem II.1.5\n",
    "\n",
    "For $b=(1,0,0)$, Let's run the Arnoldi iteration with $A$ to produce an orthonormal basis $q_1, q_2, q_3$:\n",
    "$A = \\begin{bmatrix}2 & -1 & 0 \\\\ -1 & 2 & -1 \\\\ 0 &-1 & 2 \\end{bmatrix}$\n",
    "\n",
    "* $k=1$, Let $q_1 = \\frac{b}{|b|} = (1,0,0)$.\n",
    "* $v = Aq_1 = (2, -1, 0)$\n",
    "  * $j = 1$: $h_{11}=q^T_{1}v = 2$, $v = v - h_{11}q_1 = \\begin{bmatrix} 0 \\\\-1\\\\0\\end{bmatrix}$\n",
    "* $h_{2,1} = 1$\n",
    "* $q_2 = \\frac{v}{h_{2,1}} = \\begin{bmatrix} 0 \\\\-1\\\\0\\end{bmatrix}$\n",
    "  \n",
    "* $k=2$, we have $v=Aq_2 =   \\begin{bmatrix} 1 \\\\-2\\\\1\\end{bmatrix}$\n",
    "  * $j=1$: $h_{12} = q^T_1v = 1$, $v=v-h_{12}q_1 =\\begin{bmatrix} 0 \\\\-2\\\\1\\end{bmatrix} $\n",
    "  * $j=2$: $h_{22} = q^T_2v = 2$, $v=v-h_{22}q_2 = \\begin{bmatrix} 0 \\\\0\\\\1\\end{bmatrix} $\n",
    "* $h_{3,2} = 1$\n",
    "* $q_3 = \\begin{bmatrix} 0 \\\\0\\\\1\\end{bmatrix} $\n",
    "\n",
    "So  from the calculations, we have $H =  \\begin{bmatrix} 2 & 1 \\\\-1 & -2\\\\0 & 1\\end{bmatrix}$. We can prove that $AQ_2 = Q_3H$\n",
    "\n",
    "#### Problem II.1.6\n",
    "\n",
    "We have $Q^T_2AQ_2 = \\begin{bmatrix} 1 & 0 & 0 \\\\0 & -1 & 0\\end{bmatrix} \\begin{bmatrix}2 & -1 & 0 \\\\ -1 & 2 & -1 \\\\ 0 &-1 & 2 \\end{bmatrix}\\begin{bmatrix} 1 & 0 \\\\0 & -1 \\\\ 0 & 0 \\end{bmatrix} = \\begin{bmatrix} 2 & 1 \\\\1 & 2 \\end{bmatrix}$ a triagonal matrix.\n",
    "\n",
    "#### Problem II.1.7\n",
    "\n",
    "When $n=3$, we have $A=\\begin{bmatrix}2 & -1 & 0 \\\\ -1 & 2 & -1 \\\\ 0 &-1 & 2 \\end{bmatrix}$, For the QR algorithm, we use $Q_3$ found in problem 5. That is: $A_1 = Q^{-1}_3AQ_3 = Q^T_3AQ_3 = \\begin{bmatrix} 1 & 0 & 0 \\\\0 & -1 & 0 \\\\0 & 0 & 1\\end{bmatrix} \\begin{bmatrix}2 & -1 & 0 \\\\ -1 & 2 & -1 \\\\ 0 &-1 & 2 \\end{bmatrix} \\begin{bmatrix} 1 & 0  & 0 \\\\0 & -1 & 0 \\\\ 0 & 0 & 1\\end{bmatrix} = \\begin{bmatrix}2 & 1 & 0 \\\\ 1 & 2 & 1 \\\\ 0 &1 & 2 \\end{bmatrix} $\n",
    "\n",
    "We see that the new matrix $A_1$ is still tridiagonal, with the same eigenvalues as $A$.\n",
    "\n",
    "#### Problem II.1.8\n",
    "\n",
    "With $s_1 = A_33 = 2$, we have \n",
    "\n",
    "$A - s_1I = \\begin{bmatrix}0 & -1 & 0 \\\\ -1 & 0 & -1 \\\\ 0 &-1 & 0 \\end{bmatrix} = QR = \\begin{bmatrix} 1 & 0  & 0 \\\\0 & -1 & 0 \\\\ 0 & 0 & 1\\end{bmatrix} \\begin{bmatrix} 0 & -1  & 0 \\\\1 & 0 & 1 \\\\ 0 & -1 & 0\\end{bmatrix}$\n",
    "\n",
    "We have $A_1 = RQ + s_1I = \\begin{bmatrix}2 & 1 & 0 \\\\ 1 & 2 & 1 \\\\ 0 &1 & 2 \\end{bmatrix} $ same as problem 7.\n",
    "\n",
    "#### Problem II.1.9\n",
    "\n",
    "$Ax=\\begin{bmatrix}1 \\\\ 0 \\\\ 0 \\end{bmatrix}$, so we have $x=\\begin{bmatrix}\\frac{3}{4} \\\\ \\frac{1}{2} \\\\ \\frac{1}{4} \\end{bmatrix}$.\n",
    "\n",
    "Using Conjugate Gradients, the computer program agrees with manual solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjugate Gradient Solution:  [[0.75]\n",
      " [0.5 ]\n",
      " [0.25]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def conjugate_gradient(S, b, N):\n",
    "    x = np.zeros(b.shape)\n",
    "    r = b\n",
    "    d = r\n",
    "    for k in range(1, N):\n",
    "        alpha = np.matmul(r.transpose(), r)/np.matmul(d.transpose(), np.matmul(S, d))\n",
    "        x = x + alpha * d\n",
    "        r_next = r - alpha * np.matmul(S, d)\n",
    "        u = np.matmul(r_next.transpose(), r_next)\n",
    "        d = np.matmul(r.transpose(), r)\n",
    "        beta = u/d\n",
    "        d = r_next + beta * d\n",
    "        r = r_next\n",
    "    return x\n",
    "\n",
    "A = np.array([[2,-1,0],[-1,2,-1], [0,-1,2]])\n",
    "b = np.array([1,0,0]).reshape(-1, 1)\n",
    "x = conjugate_gradient(A, b, 1000)\n",
    "print('Conjugate Gradient Solution: ', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem II.2.1\n",
    "\n",
    "Suppose $A^TAx=0$, then $Ax$ is in the nullspace of $A^T$, but $Ax$ is always in the column space of $A$, and we know $C(A)$ is perpendicular to the $N(A^T)$, so if $A^TAx=0$, then it has to be that $Ax=0$, i.e. $x$ is in the nullspace of $A$. \n",
    "\n",
    "On the other side, if we have $Ax=0$, so $x$ is in the nullspace of $A$, it's clear that $A^TAx=0$, so $x$ is in the nullspace of $A^TA$ as well. \n",
    "\n",
    "Combine both results, we see that $N(A^TA) = N(A)$\n",
    "\n",
    "#### Problem II.2.2\n",
    "\n",
    "For all matrices, we have $A=U\\Sigma V^T$, and $A^{+} = V\\Sigma^{+} U^T$, the ranks of $\\Sigma$ and $\\Sigma^{+}$ are the same, and the ranks of $A$ and $A^{+}$ are the same as $\\Sigma$ and $\\Sigma^{+}$ respectively, so $A$ and $A^{+}$ have the same rank as well.\n",
    "\n",
    "If $A$ is square, the non-zero singular values of $A^{+}$ are reciprocals of the non-zero singular values of $A$. \n",
    "\n",
    "The eigenvectors and eigenvalues of $A$ and $A^{+}$ are different.\n",
    "\n",
    "#### Problem II.2.3\n",
    "\n",
    "$A = \\sum\\sigma_i u_i v^T_i$, $A^{+}=\\sum \\frac{v_iu^T_i}{\\sigma_i}$.\n",
    "\n",
    "So we have\n",
    "\n",
    "\\begin{align*}\n",
    "A^{+}A &= \\sum_i \\frac{v_iu^T_i}{\\sigma_i}\\sum_j\\sigma_j u_j v^T_j \\\\\n",
    "&= \\sum_i \\sum_j \\frac{v_iu^T_i}{\\sigma_i}\\sigma_j u_j v^T_j\\\\\n",
    "&= \\sum_i \\frac{v_iu^T_i}{\\sigma_i}\\sigma_i u_i v^T_i\\\\\n",
    "&= \\sum_i v_i v^T_i\\\\\n",
    "&= A^{+}A\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Now $(A^{+}A)^2 = A^{+}AA^{+}A =A^{+} \\sum_i u_i u^T_i A = A^{+} \\sum_i  u_i u^T_i \\sum_j\\sigma_j u_j v^T_j = A^{+}\\sum_i \\sigma_iu_iv^T_i = \\sum_j \\frac{v_ju^T_j}{\\sigma_j} \\sum_i \\sigma_iu_iv^T_i = \\sum_j v_jv^T_j = A^{+}A$\n",
    "\n",
    "#### Problem II.2.4\n",
    "\n",
    "The matrices that have $A^{+}=A$ are matrices with singular values all equal to 1 or 0, and $u_iv^T_i= v_i u^T_i$. \n",
    "\n",
    "If we look at $I=A^{+}A = AA$, if $A$ is $m$ by $n$, then we must have $m=n$ to make the multiplication work on the right hand side. So $A$ must be square matrices.\n",
    "\n",
    "#### Problem II.2.5\n",
    "\n",
    "* (a) If $A$ has a rank $r=n$, then there are $r$ nonzeros in $\\Sigma$, these are the singular values.\n",
    "* (b) When $A$ has independent columns, we know that $A^A$ is invertible. So we have $\\Sigma=U^TAV$ and $\\Sigma^T\\Sigma = V^TA^TUU^TAV=V^TA^TAV$, the inverse of $\\Sigma^T\\Sigma$ is $(\\Sigma^T\\Sigma)^{-1} = V^T(A^TA)^{-1}V$ since $(\\Sigma^T\\Sigma)(\\Sigma^T\\Sigma)^{-1} =V^TA^TAVV^T(A^TA)^{-1}V = I$\n",
    "\n",
    "* (c) We let $\\Sigma^{+} = (\\Sigma^T\\Sigma)^{-1}\\Sigma^T = V^T(A^TA)^{-1}VV^TA^TU = V^T(A^TA)^{-1}A^TU$\n",
    "* (d) Then we have $A^{+} = (A^TA)^{-1}A^T = (V\\Sigma^2V^T)^{-1}V\\Sigma U^T = V\\Sigma^{-2}V^TV\\Sigma U^T = V\\Sigma^{-1} U^T$\n",
    "\n",
    "#### Problem II.2.6\n",
    "We want to prove $Ha=r$, let's prove that $Ha-r=0$, we have\n",
    "\n",
    "\\begin{align*}\n",
    "Ha -r &= a - 2 \\frac{(a-r)(a-r)^T}{(a-r)^T(a-r)}a - r\\\\\n",
    "&= (a-r) - 2 \\frac{(a-r)(a-r)^T}{(a-r)^T(a-r)}a \\\\\n",
    "&= \\frac{(a-r)(a-r)^T(a-r)-2(a-r)(a-r)^Ta}{(a-r)^T(a-r)}\\\\\n",
    "&= \\frac{(a-r)(a-r)^T(a+r)}{(a-r)^T(a-r)}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "We only need to prove that $(a-r)(a-r)^T(a+r)=0$. Expand the products and apply $a^Ta=r^Tr$, we have\n",
    "\n",
    "\\begin{align*}\n",
    "(a-r)(a-r)^T(a+r) &= (aa^T-ar^T-ra^T+rr^T)(a+r)\\\\\n",
    "&= aa^Ta - ar^Ta - ra^Ta + rr^Ta + aa^Tr - ar^Tr - ra^Tr + rr^Tr\\\\\n",
    "&= rr^Ta - ar^Ta + aa^Tr - ra^Tr \\\\\n",
    "&= (a-r)(a^Tr-r^Ta)\\\\\n",
    "&= 0\n",
    "\\end{align*}\n",
    "\n",
    "The second to last step, we have used $a^Tr=r^Ta$ since it's scalar. \n",
    "\n",
    "#### Problem II.2.7\n",
    "\n",
    "According to Problem 6,to have $Ha=\\begin{bmatrix}|a| \\\\ zeros\\end{bmatrix}$, we need to assign $r=\\begin{bmatrix}|a| \\\\ zeros\\end{bmatrix}$, so $v=a-r$, and $H=I-2\\frac{vv^T}{|v|^2}$.\n",
    "\n",
    "#### Problem II.2.8\n",
    "\n",
    "Let the multiple be $\\alpha$, then we should have $a^TA_2 = a^T(b-\\alpha a) = a^Tb - \\alpha a^Ta = 0$, solve for $\\alpha=2$.\n",
    "\n",
    "#### Problem II.2.9\n",
    "\n",
    "$q_1 = \\frac{a}{|a|} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix}1 \\\\ 1\\end{bmatrix}$,then $A_2 = b - (b^Tq_1)q_1 = \\begin{bmatrix}4 \\\\ 0\\end{bmatrix} - 2\\sqrt{2}\\frac{1}{\\sqrt{2}}\\begin{bmatrix}1 \\\\ 1\\end{bmatrix} = \\begin{bmatrix}2 \\\\ -2\\end{bmatrix}$, and $q_2 = \\frac{A_2}{|A_2|} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix}1 \\\\ -1\\end{bmatrix}$. In the end we have \n",
    "\n",
    "\\begin{align*}\n",
    "\\begin{bmatrix}1 & 4 \\\\ 1 & 0\\end{bmatrix} &= \\frac{1}{\\sqrt{2}}\\begin{bmatrix}1 & 1 \\\\ 1 & -1\\end{bmatrix}\\begin{bmatrix}\\sqrt{2} & b^Tq_1 \\\\ 0 & \\sqrt{8}\\end{bmatrix} \\\\\n",
    "&= \\frac{1}{\\sqrt{2}}\\begin{bmatrix}1 & 1 \\\\ 1 & -1\\end{bmatrix}\\begin{bmatrix}\\sqrt{2} & \\sqrt{8} \\\\ 0 & \\sqrt{8}\\end{bmatrix}\\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem II.2.10\n",
    "\n",
    "If $A=QR$ then $A^TA=R^TR = $ lower triangular times upper triangular matrices. Gram-Schmidt on $A$ thus corresponds to elimination on $A^TA$.\n",
    "\n",
    "#### Problem II.2.11 TODO\n",
    "\n",
    "If $Q^TQ=I$, let $Q=U\\Sigma V^T$, then we have $Q^{+}= V\\Sigma^{+} U^T$, $Q^TQ = V\\Sigma U^T U \\Sigma V^T = V \\Sigma^2 V^T = I$, multiply left by $V^T$ and right side by $V$, we have $\\Sigma^2 = I$, so $\\Sigma=I$, thus $\\Sigma^{+}=I$ and $Q^{+} = Q^T$.\n",
    "\n",
    "If $A=QR$ for invertible $R$, \n",
    "\n",
    "#### Problem II.2.12 \n",
    "\n",
    "We have $A=\\begin{bmatrix}1 & 0\\\\1 & 1 \\\\ 1 & 3 \\\\ 1 & 4\\end{bmatrix}$, $A^T=\\begin{bmatrix}1 & 1 & 1 & 1 \\\\ 0 & 1 & 3 & 4\\end{bmatrix}$, and $b=\\begin{bmatrix}0\\\\8 \\\\ 8 \\\\ 20\\end{bmatrix}$\n",
    "\n",
    "Solve for $A^TA\\hat{x}=A^Tb$, we have  $A^TA=\\begin{bmatrix}4 & 8\\\\8 & 26\\end{bmatrix}$, \n",
    "and $A^Tb = \\begin{bmatrix}36\\\\112\\end{bmatrix}$, we find $\\hat{x} = \\begin{bmatrix}1 \\\\ 4\\end{bmatrix}$, \n",
    "so the best straight line in Figure $II.3a$ is $b=1 + 4t$. \n",
    "\n",
    "The four heights at $t=0,1,3,4$ are $p=1, 5, 13, 17$, the errors are $e=b-p = -1, 3, -5, 3$, the minimum squared error $E=44$.\n",
    "\n",
    "#### Problem II.2.13\n",
    "\n",
    "We have $Ax=b$, i.e. $\\begin{bmatrix}1 & 0\\\\1 & 1 \\\\ 1 & 3 \\\\ 1 & 4\\end{bmatrix}\\begin{bmatrix}x_1 \\\\ x_2\\end{bmatrix} = \\begin{bmatrix}0\\\\8 \\\\ 8 \\\\ 20\\end{bmatrix}$, it we change the measurements to $p=1,5,13,17$, then we find $\\hat{x} = \\begin{bmatrix} 1 \\\\ 4 \\end{bmatrix}$\n",
    "\n",
    "#### Problem II.2.14\n",
    "\n",
    "$e=b-p = (-1, 3, -5, 3)$, it is perpendicular to both columns of the same matrix $A$. \n",
    "Because $e^Ta_1 = -1 + 3 -5 + 3 = 0$, and $e^Ta_2 = 0 + 3 - 15 + 12 = 0$.\n",
    "Since $e$ is perpendicular to both columns of the same matrix $A$, it is perpendicular to the column space of $A$, the shortest distance from $b$ to the column space of $A$ is $|e| = \\sqrt{1+9+25+9} = \\sqrt{44}$.\n",
    "\n",
    "#### Problem II.2.15\n",
    "\n",
    "$E=|Ax-b|^2 = (C-0)^2 + (C+D - 8)^2 + (C+3D - 8)^2 + (C+4D-20)^2$, take derivatives w.r.t. $C$ and $D$ and let the derivatives equal to 0, we have \n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial{E}}{\\partial{C}} &= 2C+2(C+D-8) + 2(C+3D-8) + 2(C+4D-20) = 0\\\\\n",
    "\\frac{\\partial{E}}{\\partial{D}} &= 0 +2(C+D-8) + 6(C+3D-8) + 8(C+4D-20) = 0\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Divide both equations by 2, we have\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial{E}}{\\partial{C}} &= C+(C+D-8) + (C+3D-8) + (C+4D-20)\\\\\n",
    "&= 4C + 8D -36 \\\\\n",
    "\\frac{\\partial{E}}{\\partial{D}} &= 0 +(C+D-8) + 3(C+3D-8) + 4(C+4D-20)\\\\\n",
    "&=8C+26D-112\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Combin into matrix form, we have $\\begin{bmatrix}4 & 8\\\\8 & 26\\end{bmatrix}\\begin{bmatrix}C\\\\D\\end{bmatrix}=\\begin{bmatrix}36\\\\112\\end{bmatrix}$, which recovers $A^TA\\hat{x} = A^Tb$.\n",
    "\n",
    "#### Problem II.2.16\n",
    "\n",
    "To find the best horizontal line to fit $b$, we have $A=\\begin{bmatrix}1\\\\1 \\\\ 1 \\\\ 1\\end{bmatrix}$, $A^T=\\begin{bmatrix}1 & 1 & 1 & 1 \\end{bmatrix}$, and $b=\\begin{bmatrix}0\\\\8 \\\\ 8 \\\\ 20\\end{bmatrix}$\n",
    "\n",
    "Solve for $A^TA\\hat{x}=A^Tb$, we have  $A^TA=\\begin{bmatrix}4 \\end{bmatrix}$, \n",
    "and $A^Tb = \\begin{bmatrix}36\\end{bmatrix}$, we find $\\hat{x} = \\begin{bmatrix}9\\end{bmatrix}$, \n",
    "so the best horizontal line fit is $b=C = 9$. \n",
    "\n",
    "The errors are $e=b-p = -9, -1, -1, 11$, total errors $E=204$\n",
    "\n",
    "\n",
    "#### Problem II.2.17\n",
    "\n",
    "$a=\\begin{bmatrix}1 \\\\ 1 \\\\ 1 \\\\1\\end{bmatrix}$, the projection of $b$ on $a$ is thus $p =\\frac{a^Tb}{a^Ta}a$, we can prove that $b-p$ is perpendicular to $a$. So we have $\\hat{x} = 9$, $p=\\hat{x}a = \\begin{bmatrix}9 \\\\ 9 \\\\ 9 \\\\9\\end{bmatrix}$, and $e=b-p = \\begin{bmatrix}-9 \\\\ -1 \\\\ -1 \\\\11\\end{bmatrix}$, and it's easy to see that $e^Ta=-9-1-1+11 = 0$, the shortest distance from $b$ to the line through $a$ is $|e| = 81 + 1 + 1 + 121 = 204$.\n",
    "\n",
    "#### Problem II.2.18\n",
    "\n",
    "To find the closest line $b=Dt$ through the origin, we have $A=\\begin{bmatrix}0\\\\1 \\\\ 3 \\\\ 4\\end{bmatrix}$, $A^T=\\begin{bmatrix}0 & 1 & 3 & 4 \\end{bmatrix}$, and $b=\\begin{bmatrix}0\\\\8 \\\\ 8 \\\\ 20\\end{bmatrix}$\n",
    "\n",
    "Solve for $A^TA\\hat{x}=A^Tb$, we have  $A^TA=\\begin{bmatrix}26 \\end{bmatrix}$, \n",
    "and $A^Tb = \\begin{bmatrix}112\\end{bmatrix}$, we find $\\hat{x} = \\begin{bmatrix}\\frac{56}{13}\\end{bmatrix}$, \n",
    "so the best horizontal line fit is $b=Dt = \\frac{56}{13}t$. \n",
    "\n",
    "The errors are $e=b-p = -\\frac{56}{13}, \\frac{48}{13}, -\\frac{64}{13}, \\frac{36}{13}$, total error $E=64.095$\n",
    "\n",
    "#### Problem II.2.19\n",
    "\n",
    "To project $b$ onto the line through $a=\\begin{bmatrix}0 \\\\ 1 \\\\ 3 \\\\4\\end{bmatrix}$, the projection of $b$ on $a$ is thus $p =\\frac{a^Tb}{a^Ta}a$, we can prove that $b-p$ is perpendicular to $a$. So we have $\\hat{x} = \\frac{56}{13}$, $p=\\hat{x}a = \\begin{bmatrix}0 \\\\ \\frac{56}{13} \\\\\\frac{168}{13} \\\\\\frac{224}{13}\\end{bmatrix}$, and $e=b-p = \\begin{bmatrix}-\\frac{56}{13}\\\\ \\frac{48}{13}\\\\ -\\frac{64}{13}\\\\ \\frac{36}{13}\\end{bmatrix}$, and it's easy to see that $e^Ta=0$, the shortest distance from $b$ to the line through $a$ is $|e| =64.095$.\n",
    "\n",
    "The best $C$ in problem 16 and the best $D$ in problem 18 do NOT agree with the best $(\\hat{C},\\hat{D})$ in problem 11-14. That is because the two columns $(1,1,1,1)$ and $(0,1,3,4)$ are not perpendicular.\n",
    "\n",
    "\n",
    "#### Problem II.2.20\n",
    "\n",
    "For the closest parabola $b=C+Dt+Et^2$, we have $Ax=b$, i.e. $\\begin{bmatrix}1 & 0 & 0 \\\\1 & 1 & 1\\\\ 1 & 3 & 9 \\\\ 1 & 4 & 16\\end{bmatrix}\\begin{bmatrix}C \\\\ D \\\\ E\\end{bmatrix} = \\begin{bmatrix}0\\\\8 \\\\ 8 \\\\ 20\\end{bmatrix}$, \n",
    "and the normal equations $A^TA\\hat{x} = A^Tb$ is: $\\begin{bmatrix}1 & 1 & 1 & 1 \\\\0 & 1 & 3 & 4\\\\ 0 & 1 & 9 & 16 \\end{bmatrix} \\begin{bmatrix}1 & 0 & 0 \\\\1 & 1 & 1\\\\ 1 & 3 & 9 \\\\ 1 & 4 & 16\\end{bmatrix}\\begin{bmatrix}C \\\\ D \\\\ E\\end{bmatrix} = \\begin{bmatrix}1 & 1 & 1 & 1 \\\\0 & 1 & 3 & 4\\\\ 0 & 1 & 9 & 16 \\end{bmatrix} \\begin{bmatrix}0\\\\8 \\\\ 8 \\\\ 20\\end{bmatrix}$\n",
    "\n",
    "In Figure II.3a, we are still finding the projection of $b$ onto the column space of $A$, which is now composed by 3 columns. \n",
    "\n",
    "#### Problem II.2.21\n",
    "\n",
    "For the closest cubic $b=C+Dt+Et^2+Ft^3$, we have $Ax=b$, i.e. $\\begin{bmatrix}1 & 0 & 0 & 0 \\\\1 & 1 & 1 & 1\\\\ 1 & 3 & 9 & 27 \\\\ 1 & 4 & 16 & 64\\end{bmatrix}\\begin{bmatrix}C \\\\ D \\\\ E \\\\ F\\end{bmatrix} = \\begin{bmatrix}0\\\\8 \\\\ 8 \\\\ 20\\end{bmatrix}$, \n",
    "\n",
    "Solve by elimination we have $C=0,D=\\frac{47}{3},E=-\\frac{28}{3},F=\\frac{5}{3}$.\n",
    "\n",
    "#### Problem II.2.22\n",
    "\n",
    "* $\\bar{t} = 2$ and $\\bar{b} = 9$, we have $C+D\\bar{t} = 1 + 4*2 = 9 = \\bar{b}$. \n",
    "\n",
    "* From the equation $A^TA\\hat{x} = A^Tb$, we have from page 136 that $A^TA\\hat{x} = \\begin{bmatrix}m & \\sum t_i \\\\ \\sum t_i & \\sum t^2_i \\end{bmatrix} \\begin{bmatrix}\\hat{C} \\\\ \\hat{D}\\end{bmatrix} = \\begin{bmatrix}\\sum b_i \\\\ \\sum b_i t_i \\end{bmatrix}$, the first equation is $m\\hat{C} + \\hat{D}\\sum t_i = \\sum b_i$, i.e. $\\hat{C} + \\hat{D} \\bar{t} = \\bar{b}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
